{
	"nodes":[
		{"type":"file","file":"ðŸŒ³ Forest/100 STEM MOC/110 Computer Science MOC/Programming Languages/C++/C++ Thread Model.md","id":"a269dd5aa510fb91","x":60,"y":-2060,"width":620,"height":320},
		{"type":"file","file":"ðŸŒ³ Forest/100 STEM MOC/110 Computer Science MOC/Systems MOC/Concurrency MOC/C++ Data Race Definition.md","id":"3970c37bec2013e3","x":-520,"y":-2220,"width":440,"height":400},
		{"type":"file","file":"ðŸŒ³ Forest/100 STEM MOC/110 Computer Science MOC/Programming Languages/C++/C++ Memory Model.md","id":"d87481a3c33db06e","x":520,"y":-1459,"width":612,"height":634},
		{"type":"file","file":"ðŸŒ³ Forest/100 STEM MOC/110 Computer Science MOC/Systems MOC/Concurrency MOC/Memory Model.md","id":"3239f75e1051ff93","x":760,"y":-355,"width":568,"height":720},
		{"type":"file","file":"ðŸŒ³ Forest/100 STEM MOC/110 Computer Science MOC/Systems MOC/Concurrency MOC/Process Synchronization.md","id":"b1163664c40da8c7","x":626,"y":500,"width":400,"height":400},
		{"type":"file","file":"ðŸŒ³ Forest/100 STEM MOC/110 Computer Science MOC/Systems MOC/Concurrency MOC/The need for a memory model for concurrent programming.md","id":"9cf4364c4f22d51c","x":349,"y":121,"width":371,"height":359},
		{"type":"link","url":"https://en.cppreference.com/w/cpp/language/memory_model","id":"70c0c834907e74a1","x":-380,"y":-1700,"width":780,"height":680},
		{"type":"file","file":"ðŸŒ³ Forest/100 STEM MOC/110 Computer Science MOC/Systems MOC/Concurrency MOC/Goals of Concurrent Programming.md","id":"18e1a1c6453bb951","x":248,"y":620,"width":378,"height":360},
		{"type":"file","file":"ðŸŒ³ Forest/100 STEM MOC/110 Computer Science MOC/Systems MOC/Concurrency MOC/C++ Memory Order.md","id":"abca546efbe309b4","x":-480,"y":800,"width":480,"height":500},
		{"type":"file","file":"ðŸŒ³ Forest/100 STEM MOC/110 Computer Science MOC/Systems MOC/Concurrency MOC/Modification Order in C++.md","id":"7da0254a12bbb4a0","x":-608,"y":1393,"width":428,"height":347},
		{"type":"text","text":"Although the Modification Order for a particular atomic is global, without synchronisation its not so easy to deduce the modification order of other atomics.","id":"594314d25bce5cd6","x":-95,"y":1338,"width":415,"height":162},
		{"type":"text","text":"**When you use synchronization primitives such as mutexes, locks, and condition variables, the compiler and hardware are restricted from reordering memory operations in a way that would violate the synchronization guarantees.**","id":"53e4950f69056d7b","x":-2371,"y":-1300,"width":419,"height":208},
		{"type":"file","file":"ðŸŒ³ Forest/100 STEM MOC/110 Computer Science MOC/Systems MOC/Concurrency MOC/Hardware Memory Model.md","id":"d56791d4e0c22fd2","x":1480,"y":-322,"width":720,"height":719},
		{"type":"link","url":"https://en.cppreference.com/w/cpp/atomic/memory_order","id":"5202e9729b2c73ec","x":150,"y":1614,"width":820,"height":589},
		{"type":"text","text":"Foundations of what it means for operations to become visible in different and same threads in C++\n\n- What does it mean for a operations to appear in the same or different orders on different threads?\n- The game of concurrency.\n\t- Need to create invariants that provide minimum guarantees AS TO THE **VISIBILITY** OF EVENTS!\n\t- **CREATING ORDERINGS**\n- Shared Boolean vs std::atomic \n\n\n\nWhat is strong vs weak consistency\n\nWhat does it mean for something to become visible in another thread?\n\n---\n## Themes:\n- [[Order Theory]]\n- [[Memory Model]]s and their interaction with [[Computer Architecture]]\n- [[Synchronization Primitives]]","id":"f5ac7fd956ee16cf","x":-800,"y":-832,"width":479,"height":682,"color":"4"},
		{"type":"text","text":"1. Acquiring a mutex (lock) acts as an acquire barrier, ensuring that memory operations after the mutex acquisition in the current thread become visible to other threads that acquire the same mutex later.\n2. Releasing a mutex (unlock) acts as a release barrier, ensuring that memory operations before the mutex release in the current thread become visible to other threads that release the same mutex.","id":"6ce17fdc4c63313a","x":-2685,"y":-960,"width":628,"height":378},
		{"type":"file","file":"ðŸŒ³ Forest/100 STEM MOC/110 Computer Science MOC/Systems MOC/Concurrency MOC/Synchronises With Relation.md","id":"3b45950ce853b271","x":-2685,"y":-175,"width":727,"height":855},
		{"type":"text","text":"[[Goals of Concurrent Programming]] are achieved by establishing the [[Order of Visibility]] of memory operations.\n\nOne may consider [[Critical Section]] as a form of macroscopic ordering: a block of operations (those inside the critical region) must execute prior to another.","id":"2e5e9f94041aeb9f","x":-765,"y":21,"width":371,"height":283,"color":"3"},
		{"type":"file","file":"ðŸŒ³ Forest/100 STEM MOC/110 Computer Science MOC/Systems MOC/Concurrency MOC/Program Order Relation.md","id":"31f03feb5a40a9e2","x":-3480,"y":-203,"width":627,"height":504},
		{"type":"file","file":"ðŸŒ³ Forest/100 STEM MOC/110 Computer Science MOC/Systems MOC/Concurrency MOC/Happens Before Relation.md","id":"a643794fc3dc1d5a","x":-3613,"y":619,"width":760,"height":562},
		{"type":"file","file":"ðŸŒ³ Forest/100 STEM MOC/110 Computer Science MOC/Systems MOC/Concurrency MOC/Why order of execution may not be the same as order of visibility.md","id":"4efc2c8989f7c243","x":-3166,"y":1284,"width":566,"height":456},
		{"type":"text","text":"Order of execution\n\n(something that we can consider on a thread)","id":"51e5580d4a69f950","x":-2400,"y":980,"width":250,"height":155,"color":"1"},
		{"type":"link","url":"https://preshing.com/20120625/memory-ordering-at-compile-time/","id":"24c05bf46e076350","x":-3743,"y":2533,"width":383,"height":320},
		{"type":"text","text":"## Memory Ordering at Compile Time","id":"cffcc32e142e76a8","x":-3360,"y":2160,"width":391,"height":57},
		{"type":"text","text":"## Memory Ordering at Run Time","id":"1772224b6ba10779","x":-1593,"y":2132,"width":333,"height":57},
		{"type":"text","text":"**Sources of Reordering**: Compiler Optimizations (to better support **pipelining**, Processor execution reordering, Memory Coherence\n\n**Ways to address at compile time**: \n- **Compiler Optimization Barriers**\n- **Memory Orderings** (implicit barriers)","id":"8985b2f1b404f53e","x":-2480,"y":2413,"width":367,"height":240},
		{"type":"file","file":"ðŸŒ³ Forest/100 STEM MOC/110 Computer Science MOC/Compilers and Optimisations MOC/Out of Thin Air Transformations.md","id":"6da57267271b033d","x":-3200,"y":2646,"width":463,"height":414},
		{"type":"file","file":"ðŸŒ³ Forest/100 STEM MOC/110 Computer Science MOC/Programming Languages/C++/As-if Rule.md","id":"87ca237b6e6b68bb","x":-2600,"y":2660,"width":400,"height":400},
		{"type":"file","file":"ðŸŒ³ Forest/100 STEM MOC/110 Computer Science MOC/Systems MOC/Concurrency MOC/Analogy of The Central Repository.md","id":"b6ad48ae7407915e","x":-1491,"y":3040,"width":611,"height":460},
		{"type":"text","text":"## Canonical Example of Relaxed Memory Models being tricky:\n\n```cpp\nx = 1\nr1 = y\n```\n\n```cpp\ny = 1\nr2 = x\n```\n\nBoth x and y are initially 0. It is possible in a relaxed memory model for both r1 and r2 to be 0 at the end simply because the **writes of the other threads do not become visible in each other (because cache is not flushed for example)**","id":"842714e021021843","x":-2047,"y":2981,"width":427,"height":439},
		{"type":"text","text":"### Types of Memory Barrier\n\n","id":"67ad49db579bc61a","x":-833,"y":2978,"width":493,"height":562},
		{"type":"link","url":"https://www.cl.cam.ac.uk/~pes20/weakmemory/ec2.pdf","id":"f3248db030f43f96","x":-1656,"y":3685,"width":400,"height":400},
		{"type":"text","text":"## LoadLoad Memory Barrier\n```cpp\na = x\n// LOADLOAD\nb = y\n```\nA loadload barrier ensures that the read of y does not return a value less recent than x.","id":"a2aaf56482aa4f41","x":-755,"y":2527,"width":355,"height":413},
		{"type":"text","text":"## StoreStore Memory Barrier\n```cpp\nx = 1\n// STORESTORE\ny = 1\n```\nA storestore barrier ensures that the write y does not become visible prior to the write to x.","id":"0262466b6023e24d","x":-340,"y":2527,"width":320,"height":413},
		{"type":"link","url":"https://preshing.com/20120710/memory-barriers-are-like-source-control-operations/","id":"d8be95a764523301","x":-1813,"y":2300,"width":553,"height":579},
		{"type":"text","text":"1. **memory_order_relaxed**: No specific ordering constraints are enforced. This corresponds to no barriers being applied, allowing the most freedom for the compiler and hardware to reorder memory operations.\n    \n2. **memory_order_release**Â andÂ **memory_order_acquire**: These memory orders correspond to the StoreStore and LoadLoad barriers, respectively. TheÂ `memory_order_release`Â enforces that all store operations before the atomic operation are visible to other threads before the atomic operation itself. TheÂ `memory_order_acquire`Â ensures that all load operations after the atomic operation are visible to other threads after the atomic operation itself.\n    \n3. **memory_order_acq_rel**: This memory order combines the effects ofÂ `memory_order_release`Â andÂ `memory_order_acquire`, effectively acting as both the StoreStore and LoadLoad barriers. This order is particularly useful for atomic read-modify-write operations (e.g.,Â `fetch_add`), where you want to enforce both ordering constraints.\n    \n4. **memory_order_seq_cst**: This is the strongest memory order and corresponds to the StoreLoad barrier. It enforces a total order on all memory operations, ensuring that all store and load operations before the atomic operation are visible to other threads before all store and load operations after the atomic operation.","id":"cbe8f976817944eb","x":-647,"y":3659,"width":727,"height":581},
		{"type":"text","text":"Yes, cache coherence protocols play a crucial role in ensuring a consistent view of memory in multi-core processors, and they do so in a way that you might describe as preventing you from \"going back in time.\"\n\nIn a multi-core system, each processor core has its own private cache, and all cores can access shared main memory. This leads to the potential problem of keeping the cached data consistent: if one core modifies a piece of data, the change needs to propagate to all other cores that have cached that data. This is what cache coherence protocols address.\n\nConsider a simple example. Let's say two cores, A and B, both read the same value from memory into their private caches. Then core A changes this value. The cache coherence protocol ensures that if B subsequently tries to read that value again, it gets the updated value that A wrote, not the old value that B originally read. In this sense, B cannot \"go back in time\" and see an old, stale value.\n\nHowever, while cache coherence ensures this level of consistency, it's important to understand that it operates at the hardware level and doesn't directly control the ordering of high-level operations in a multi-threaded program. In C++, for example, the memory model and atomic operations with different memory orders provide high-level abstractions to coordinate ordering and visibility of operations across threads.\n\nSo, even though cache coherence prevents one kind of \"going back in time\" (seeing stale data) at the hardware level, it doesn't prevent all potential inconsistencies in a multi-threaded program. High-level synchronization and ordering mechanisms are needed to fully control the order and visibility of operations in such programs.","id":"f3f130e675fa0658","x":277,"y":3290,"width":693,"height":795},
		{"type":"file","file":"ðŸŒ³ Forest/100 STEM MOC/110 Computer Science MOC/Systems MOC/Concurrency MOC/Modification Order.md","id":"38f7e0bf850c895f","x":-1233,"y":1835,"width":400,"height":148},
		{"type":"file","file":"ðŸŒ³ Forest/100 STEM MOC/110 Computer Science MOC/Systems MOC/Concurrency MOC/Sequential Consistency.md","id":"997e3332f5ad3d32","x":248,"y":2540,"width":778,"height":661},
		{"type":"text","text":"## Atomic Weapons\n- Simplistic mental model of computer is much simpler than in reality (multicore, multiple levels of cache)","id":"4acfec3905af32fa","x":-1358,"y":900,"width":603,"height":640},
		{"type":"text","text":"**Register Allocation  / Register Assignment** Compiler optimization can create different behaviour in MT environment.","id":"f669da5f259c4a68","x":-3219,"y":2440,"width":419,"height":78},
		{"type":"text","text":"","id":"11e74cdd9129cf52","x":-685,"y":515,"width":250,"height":60},
		{"type":"text","text":"**Order of Visibility**\n\n(something that we can consider across threads)","id":"78ec86188567e0d1","x":-1056,"y":700,"width":292,"height":150},
		{"type":"file","file":"ðŸŒ³ Forest/100 STEM MOC/110 Computer Science MOC/Architecture and Hardware MOC/Cache Coherence.md","id":"c422aca6553eb8d7","x":1120,"y":1253,"width":440,"height":567},
		{"type":"file","file":"ðŸŒ³ Forest/100 STEM MOC/110 Computer Science MOC/Compilers and Optimisations MOC/Barriers in Assembly.md","id":"26f73059aba0fcab","x":1292,"y":875,"width":388,"height":345},
		{"type":"file","file":"ðŸŒ³ Forest/100 STEM MOC/110 Computer Science MOC/Systems MOC/Concurrency MOC/Consistency Model.md","id":"0bab5e7cb8b6b9eb","x":626,"y":1041,"width":400,"height":179},
		{"type":"text","text":"**Coherence vs Consistency**","id":"9ca3f830a10056e8","x":703,"y":1338,"width":246,"height":50},
		{"type":"file","file":"ðŸŒ³ Forest/100 STEM MOC/110 Computer Science MOC/Architecture and Hardware MOC/Lock x86 Instruction.md","id":"c05a79b740d598a5","x":1800,"y":887,"width":400,"height":501},
		{"id":"8501740feab19439","x":1820,"y":1460,"width":580,"height":400,"type":"file","file":"ðŸŒ³ Forest/100 STEM MOC/110 Computer Science MOC/Architecture and Hardware MOC/Ways to improve performance on memory bus lock assertions.md"},
		{"id":"e6ab2f743ed1db41","x":1456,"y":1988,"width":624,"height":612,"type":"text","text":"## Further Reading:\n- [ ] **\"Computer Architecture: A Quantitative Approach\" by John L. Hennessy and David A. Patterson**: This is a comprehensive book that covers many aspects of computer architecture in depth. Specifically, Chapter 5 discusses memory hierarchy designs and provides insight into cache coherence protocols like MESI.\n- [ ] **\"Modern Operating Systems\" by Andrew S. Tanenbaum**: This book covers a broad range of concepts related to operating systems, including memory management and synchronization. Chapter 2 discusses memory barriers and atomic operations in the context of process synchronization.  \n- [ ] **\"C++ Concurrency in Action\" by Anthony Williams**: This book provides a detailed discussion on various aspects of concurrency in C++, including memory models, atomic operations, and memory fences.\n- [ ] **Intel 64 and IA-32 Architectures Software Developer Manuals**: These manuals from Intel provide detailed information about memory barriers andÂ `lock`Â instructions in x86 architecture.\n- [ ] **\"The Art of Multiprocessor Programming\" by Maurice Herlihy and Nir Shavit**: This book is specifically focused on concurrent programming and covers techniques like lock-free programming, which can help reduce the need for memory barriers."}
	],
	"edges":[
		{"id":"7a608e64cbf7b278","fromNode":"d87481a3c33db06e","fromSide":"top","toNode":"a269dd5aa510fb91","toSide":"right"},
		{"id":"26ecdc2914c892ce","fromNode":"a269dd5aa510fb91","fromSide":"left","toNode":"3970c37bec2013e3","toSide":"right"},
		{"id":"380633c1abef98a4","fromNode":"d87481a3c33db06e","fromSide":"bottom","toNode":"abca546efbe309b4","toSide":"top"},
		{"id":"eec92c4532bfd520","fromNode":"5202e9729b2c73ec","fromSide":"left","toNode":"abca546efbe309b4","toSide":"bottom"},
		{"id":"d4a43c7803b82fc4","fromNode":"3239f75e1051ff93","fromSide":"top","toNode":"d87481a3c33db06e","toSide":"bottom"},
		{"id":"9f12a345b9658c3e","fromNode":"b1163664c40da8c7","fromSide":"bottom","toNode":"0bab5e7cb8b6b9eb","toSide":"top"},
		{"id":"7a9a936060978d29","fromNode":"18e1a1c6453bb951","fromSide":"right","toNode":"b1163664c40da8c7","toSide":"left"},
		{"id":"351a3871bf74871d","fromNode":"18e1a1c6453bb951","fromSide":"top","toNode":"9cf4364c4f22d51c","toSide":"bottom"},
		{"id":"6832b885085e0f7b","fromNode":"9cf4364c4f22d51c","fromSide":"top","toNode":"3239f75e1051ff93","toSide":"left"},
		{"id":"d69aa76ce8fffa10","fromNode":"d87481a3c33db06e","fromSide":"left","toNode":"70c0c834907e74a1","toSide":"right"},
		{"id":"0fa3dc323991938a","fromNode":"abca546efbe309b4","fromSide":"bottom","toNode":"7da0254a12bbb4a0","toSide":"top"},
		{"id":"3ba89c511697b0c9","fromNode":"7da0254a12bbb4a0","fromSide":"left","toNode":"38f7e0bf850c895f","toSide":"right"},
		{"id":"ef9929a996909bed","fromNode":"3239f75e1051ff93","fromSide":"right","toNode":"d56791d4e0c22fd2","toSide":"left"},
		{"id":"23307643c4544a5c","fromNode":"6da57267271b033d","fromSide":"right","toNode":"87ca237b6e6b68bb","toSide":"left"},
		{"id":"1d91148a1cacb758","fromNode":"24c05bf46e076350","fromSide":"right","toNode":"6da57267271b033d","toSide":"left"},
		{"id":"bb25b78b537892f2","fromNode":"24c05bf46e076350","fromSide":"top","toNode":"cffcc32e142e76a8","toSide":"left"},
		{"id":"e5921100ce3822fc","fromNode":"cffcc32e142e76a8","fromSide":"right","toNode":"8985b2f1b404f53e","toSide":"left"},
		{"id":"2caf379d6621feb9","fromNode":"1772224b6ba10779","fromSide":"left","toNode":"8985b2f1b404f53e","toSide":"right"},
		{"id":"2e7bf1b25386ea72","fromNode":"d8be95a764523301","fromSide":"top","toNode":"1772224b6ba10779","toSide":"left"},
		{"id":"853f036f1e32870a","fromNode":"d8be95a764523301","fromSide":"bottom","toNode":"b6ad48ae7407915e","toSide":"top"},
		{"id":"00c0ba8f5e3e7d60","fromNode":"b6ad48ae7407915e","fromSide":"left","toNode":"842714e021021843","toSide":"right"},
		{"id":"8a31cce76018ac19","fromNode":"38f7e0bf850c895f","fromSide":"bottom","toNode":"b6ad48ae7407915e","toSide":"top"},
		{"id":"4e98245872ceb7c1","fromNode":"c422aca6553eb8d7","fromSide":"left","toNode":"9ca3f830a10056e8","toSide":"right"},
		{"id":"e0db93708edf1b6e","fromNode":"9ca3f830a10056e8","fromSide":"top","toNode":"0bab5e7cb8b6b9eb","toSide":"bottom"},
		{"id":"bc06f120bd6324d2","fromNode":"c05a79b740d598a5","fromSide":"left","toNode":"26f73059aba0fcab","toSide":"right"},
		{"id":"fcb95ee699804a85","fromNode":"8501740feab19439","fromSide":"top","toNode":"c05a79b740d598a5","toSide":"bottom"}
	]
}