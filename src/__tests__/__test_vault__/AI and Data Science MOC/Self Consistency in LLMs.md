---
type: note
created: Sunday 11 Feb 2024
tags: 
---
[[Self-Consistency Improves Chain of Thought Reasoning in Language Models.pdf]]

> [!IDEA]
> Create a [[Few Shot]] [[Chain of Thought Prompting]] to trigger different reasoning paths. Then sample a couple of responses and finally majority vote

> [!Quote]
> A salient aspect of humanity is that people think differently. It is natural to suppose that in tasks requiring deliberate thinking, there are likely several ways to attack the problem. We propose that such a process can be simulated in language models via sampling from the language modelâ€™s decoder.

[[AI research takes inspiration from nature]]


